{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e432ca61-1e33-4ccb-ba9d-cc89a4e4a857",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Libraries & variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "15ed21c7-3aa6-4004-86c6-092a258e7f50",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Import\n",
    "from datetime import datetime\n",
    "from pyspark.sql.functions import explode, col, lit, split\n",
    "\n",
    "# Variables\n",
    "blob_account_name = \"streamersdata\"\n",
    "blob_container_name = \"staging\"\n",
    "blob_sas_token = \"<blob_sas_token>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a025e36c-4467-4e2c-8dec-75beec163945",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Define the JDBC URL and connection properties\n",
    "jdbc_url = \"jdbc:sqlserver://streamers-sqlserver.database.windows.net:1433;database=streamers-sqldb\"\n",
    "connection_properties = {\n",
    "    \"user\": \"<USERNAME>\",\n",
    "    \"password\": \"<PASSWORD\",\n",
    "    \"driver\": \"com.microsoft.sqlserver.jdbc.SQLServerDriver\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fed5abe8-d717-4928-8b6d-2bc5cec8a592",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The SAS token is valid until 2024-12-20T17:03:16Z.\n"
     ]
    }
   ],
   "source": [
    "# Check if the token is still valid\n",
    "expiry_date_str = blob_sas_token.split(\"&se=\")[1].split(\"&\")[0]\n",
    "expiry_date = datetime.strptime(expiry_date_str, \"%Y-%m-%dT%H:%M:%SZ\")\n",
    "current_date = datetime.utcnow()\n",
    "\n",
    "if current_date > expiry_date:\n",
    "    raise Exception(\"The SAS token is not valid anymore.\")\n",
    "else:\n",
    "    print(f\"The SAS token is valid until {expiry_date_str}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3ac03ce3-9f2a-4eb4-a840-04ea419fb224",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# File mounting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "35fbb48a-fd27-4b5a-abe8-cc409c248304",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/staging has been unmounted.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>path</th><th>name</th><th>size</th><th>modificationTime</th></tr></thead><tbody><tr><td>dbfs:/mnt/staging/amazon_prime.csv</td><td>amazon_prime.csv</td><td>6868017</td><td>1734100958000</td></tr><tr><td>dbfs:/mnt/staging/apple_tv.csv</td><td>apple_tv.csv</td><td>1394527</td><td>1734100958000</td></tr><tr><td>dbfs:/mnt/staging/hbo_max.csv</td><td>hbo_max.csv</td><td>1113776</td><td>1734100958000</td></tr><tr><td>dbfs:/mnt/staging/hulu.csv</td><td>hulu.csv</td><td>691846</td><td>1734100958000</td></tr><tr><td>dbfs:/mnt/staging/netflix.csv</td><td>netflix.csv</td><td>5044133</td><td>1734100959000</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "dbfs:/mnt/staging/amazon_prime.csv",
         "amazon_prime.csv",
         6868017,
         1734100958000
        ],
        [
         "dbfs:/mnt/staging/apple_tv.csv",
         "apple_tv.csv",
         1394527,
         1734100958000
        ],
        [
         "dbfs:/mnt/staging/hbo_max.csv",
         "hbo_max.csv",
         1113776,
         1734100958000
        ],
        [
         "dbfs:/mnt/staging/hulu.csv",
         "hulu.csv",
         691846,
         1734100958000
        ],
        [
         "dbfs:/mnt/staging/netflix.csv",
         "netflix.csv",
         5044133,
         1734100959000
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "path",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "size",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "modificationTime",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Mount point\n",
    "mount_point = f\"/mnt/{blob_container_name}\"\n",
    "\n",
    "# Unmount if already mounted\n",
    "if mount_point in [mnt.mountPoint for mnt in dbutils.fs.mounts()]:\n",
    "    dbutils.fs.unmount(mount_point)\n",
    "\n",
    "# Mount the Blob Storage\n",
    "dbutils.fs.mount(\n",
    "    source=f\"wasbs://{blob_container_name}@{blob_account_name}.blob.core.windows.net\",\n",
    "    mount_point=mount_point,\n",
    "    extra_configs={f\"fs.azure.sas.{blob_container_name}.{blob_account_name}.blob.core.windows.net\": blob_sas_token}\n",
    ")\n",
    "\n",
    "# List files in the container\n",
    "display(dbutils.fs.ls(mount_point))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3f9755d1-0636-48b7-a74b-5dff12fcc77c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Dataframe creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a8a782f6-d733-4bf7-95b6-02d64ad032cf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# CSV to DataFrame function\n",
    "def load_csv_to_df(relative_path):\n",
    "    csv_file_path = f\"{mount_point}/{relative_path}\"\n",
    "    return spark.read.format(\"csv\").option(\"header\", \"true\").load(csv_file_path)\n",
    "\n",
    "# Relative paths\n",
    "amazon_relative_path = \"amazon_prime.csv\"\n",
    "apple_relative_path = \"apple_tv.csv\"\n",
    "hbo_relative_path = \"hbo_max.csv\"\n",
    "hulu_relative_path = \"hulu.csv\"\n",
    "netflix_relative_path = \"netflix.csv\"\n",
    "\n",
    "# Load DataFrames\n",
    "amazon_df = load_csv_to_df(amazon_relative_path)\n",
    "apple_df = load_csv_to_df(apple_relative_path)\n",
    "hbo_df = load_csv_to_df(hbo_relative_path)\n",
    "hulu_df = load_csv_to_df(hulu_relative_path)\n",
    "netflix_df = load_csv_to_df(netflix_relative_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0132d23f-f719-4198-a5e8-c208f2b74963",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Dataframe cleaning & transformation\n",
    "The dataframes need to be transformed for easy processing.\n",
    "1. I remove all the records without data. If the columns title, imdbId, imdbAverageRating or imdbNumVotes contain Null the row is deleted.\n",
    "2. The data in the dataframes are in string format. So I change them to integer or float if needed.\n",
    "3. Null's in the releaseYear column are replaced with 9999\n",
    "4. A new column is added with the platform name.\n",
    "5. Last step is combining. Luckely the five different CSV files follow the same template. So combining them is not to difficult."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "54f6caf8-250e-4910-9b68-7c1ea90a1764",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Function to transform DataFrame\n",
    "def transform_df(df, platform_name):\n",
    "    df = df.withColumn(\"platform\", lit(platform_name))\n",
    "    df = df.filter(\n",
    "        col(\"title\").isNotNull() &\n",
    "        col(\"imdbId\").isNotNull() &\n",
    "        col(\"imdbAverageRating\").isNotNull() &\n",
    "        col(\"imdbNumVotes\").isNotNull()\n",
    "    )\n",
    "    df = df.withColumn(\"releaseYear\", col(\"releaseYear\").cast(\"integer\"))\n",
    "    df = df.withColumn(\"imdbNumVotes\", col(\"imdbNumVotes\").cast(\"integer\"))\n",
    "    df = df.withColumn(\"imdbAverageRating\", col(\"imdbAverageRating\").cast(\"float\"))\n",
    "    df = df.fillna({\n",
    "        \"type\": \"Unknown\",\n",
    "        \"genres\": \"Unknown\",\n",
    "        \"releaseYear\": 9999,\n",
    "        \"availableCountries\": \"Unknown\"\n",
    "    })\n",
    "    return df\n",
    "\n",
    "# Apply the transformation function to each DataFrame\n",
    "amazon_df_cleaned = transform_df(amazon_df, \"Amazon Prime\")\n",
    "apple_df_cleaned = transform_df(apple_df, \"Apple TV Plus\")\n",
    "hbo_df_cleaned = transform_df(hbo_df, \"HBO Max\")\n",
    "hulu_df_cleaned = transform_df(hulu_df, \"Hulu\")\n",
    "netflix_df_cleaned = transform_df(netflix_df, \"Netflix\")\n",
    "\n",
    "# Combine the DataFrames\n",
    "combined_df = amazon_df_cleaned.unionByName(apple_df_cleaned) \\\n",
    "                               .unionByName(hbo_df_cleaned) \\\n",
    "                               .unionByName(hulu_df_cleaned) \\\n",
    "                               .unionByName(netflix_df_cleaned)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b2eabae3-fd0e-4bed-b0d8-125457bb906f",
     "showTitle": false,
     "tableResultSettingsMap": {
      "0": {
       "filterBlob": "{\"filterGroups\":[],\"syncTimestamp\":1733389662095}",
       "tableResultIndex": 0
      }
     },
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>title</th><th>type</th><th>genres</th><th>releaseYear</th><th>imdbId</th><th>imdbAverageRating</th><th>imdbNumVotes</th><th>availableCountries</th><th>platform</th></tr></thead><tbody><tr><td>Blondie</td><td>movie</td><td>Comedy, Family</td><td>1938</td><td>tt0029927</td><td>6.9</td><td>889</td><td>US, ZA</td><td>Amazon Prime</td></tr><tr><td>Ariel</td><td>movie</td><td>Comedy, Crime, Romance</td><td>1988</td><td>tt0094675</td><td>7.4</td><td>8819</td><td>JP</td><td>Amazon Prime</td></tr><tr><td>Four Rooms</td><td>movie</td><td>Comedy</td><td>1995</td><td>tt0113101</td><td>6.7</td><td>112815</td><td>AT, DE</td><td>Amazon Prime</td></tr><tr><td>Judgment Night</td><td>movie</td><td>Action, Crime, Drama</td><td>1993</td><td>tt0107286</td><td>6.6</td><td>19366</td><td>US</td><td>Amazon Prime</td></tr><tr><td>Forrest Gump</td><td>movie</td><td>Drama, Romance</td><td>1994</td><td>tt0109830</td><td>8.8</td><td>2327333</td><td>AD, AT, CU, DE, FR, GF, IN, JP, MC, PF, SN</td><td>Amazon Prime</td></tr><tr><td>Citizen Kane</td><td>movie</td><td>Drama, Mystery</td><td>1941</td><td>tt0033467</td><td>8.3</td><td>474976</td><td>AD, CA, ES, IN, JP</td><td>Amazon Prime</td></tr><tr><td>Dancer in the Dark</td><td>movie</td><td>Crime, Drama, Musical</td><td>2000</td><td>tt0168629</td><td>7.9</td><td>118972</td><td>DK, FI, NO, SE</td><td>Amazon Prime</td></tr><tr><td>The Dark</td><td>movie</td><td>Drama, Fantasy, Horror</td><td>2005</td><td>tt0411267</td><td>5.3</td><td>11567</td><td>CA, US</td><td>Amazon Prime</td></tr><tr><td>Metropolis</td><td>movie</td><td>Drama, Sci-Fi</td><td>1927</td><td>tt0017136</td><td>8.3</td><td>190864</td><td>DK, IT, NO, SE, SM, VA</td><td>Amazon Prime</td></tr><tr><td>My Life Without Me</td><td>movie</td><td>Drama, Romance</td><td>2003</td><td>tt0314412</td><td>7.4</td><td>26072</td><td>GB, GG</td><td>Amazon Prime</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "Blondie",
         "movie",
         "Comedy, Family",
         1938,
         "tt0029927",
         6.9,
         889,
         "US, ZA",
         "Amazon Prime"
        ],
        [
         "Ariel",
         "movie",
         "Comedy, Crime, Romance",
         1988,
         "tt0094675",
         7.4,
         8819,
         "JP",
         "Amazon Prime"
        ],
        [
         "Four Rooms",
         "movie",
         "Comedy",
         1995,
         "tt0113101",
         6.7,
         112815,
         "AT, DE",
         "Amazon Prime"
        ],
        [
         "Judgment Night",
         "movie",
         "Action, Crime, Drama",
         1993,
         "tt0107286",
         6.6,
         19366,
         "US",
         "Amazon Prime"
        ],
        [
         "Forrest Gump",
         "movie",
         "Drama, Romance",
         1994,
         "tt0109830",
         8.8,
         2327333,
         "AD, AT, CU, DE, FR, GF, IN, JP, MC, PF, SN",
         "Amazon Prime"
        ],
        [
         "Citizen Kane",
         "movie",
         "Drama, Mystery",
         1941,
         "tt0033467",
         8.3,
         474976,
         "AD, CA, ES, IN, JP",
         "Amazon Prime"
        ],
        [
         "Dancer in the Dark",
         "movie",
         "Crime, Drama, Musical",
         2000,
         "tt0168629",
         7.9,
         118972,
         "DK, FI, NO, SE",
         "Amazon Prime"
        ],
        [
         "The Dark",
         "movie",
         "Drama, Fantasy, Horror",
         2005,
         "tt0411267",
         5.3,
         11567,
         "CA, US",
         "Amazon Prime"
        ],
        [
         "Metropolis",
         "movie",
         "Drama, Sci-Fi",
         1927,
         "tt0017136",
         8.3,
         190864,
         "DK, IT, NO, SE, SM, VA",
         "Amazon Prime"
        ],
        [
         "My Life Without Me",
         "movie",
         "Drama, Romance",
         2003,
         "tt0314412",
         7.4,
         26072,
         "GB, GG",
         "Amazon Prime"
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "title",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "type",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "genres",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "releaseYear",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "imdbId",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "imdbAverageRating",
         "type": "\"float\""
        },
        {
         "metadata": "{}",
         "name": "imdbNumVotes",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "availableCountries",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "platform",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display the combined DataFrame\n",
    "display(combined_df.limit(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d9559a9d-485e-4056-ad46-c287a4c02ab1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Content DataFrame\n",
    "The content dataframe contains the unique content from all the platforms combined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6129b71b-91f5-460e-9060-c1c053c0b384",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>title</th><th>type</th><th>releaseYear</th><th>imdbId</th><th>imdbAverageRating</th><th>imdbNumVotes</th></tr></thead><tbody><tr><td>Ariel</td><td>movie</td><td>1988</td><td>tt0094675</td><td>7.4</td><td>8819</td></tr><tr><td>Blondie</td><td>movie</td><td>1938</td><td>tt0029927</td><td>6.9</td><td>889</td></tr><tr><td>Forrest Gump</td><td>movie</td><td>1994</td><td>tt0109830</td><td>8.8</td><td>2327333</td></tr><tr><td>Four Rooms</td><td>movie</td><td>1995</td><td>tt0113101</td><td>6.7</td><td>112815</td></tr><tr><td>Judgment Night</td><td>movie</td><td>1993</td><td>tt0107286</td><td>6.6</td><td>19366</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "Ariel",
         "movie",
         1988,
         "tt0094675",
         7.4,
         8819
        ],
        [
         "Blondie",
         "movie",
         1938,
         "tt0029927",
         6.9,
         889
        ],
        [
         "Forrest Gump",
         "movie",
         1994,
         "tt0109830",
         8.8,
         2327333
        ],
        [
         "Four Rooms",
         "movie",
         1995,
         "tt0113101",
         6.7,
         112815
        ],
        [
         "Judgment Night",
         "movie",
         1993,
         "tt0107286",
         6.6,
         19366
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "title",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "type",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "releaseYear",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "imdbId",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "imdbAverageRating",
         "type": "\"float\""
        },
        {
         "metadata": "{}",
         "name": "imdbNumVotes",
         "type": "\"integer\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Select the specified columns from combined_df\n",
    "content_df = combined_df.select(\"title\", \"type\", \"releaseYear\", \"imdbId\", \"imdbAverageRating\", \"imdbNumVotes\").distinct()\n",
    "\n",
    "# Display the content_df DataFrame\n",
    "display(content_df.limit(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4654a6b8-d669-4db0-b89c-9f6f684440ed",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Genre DataFrame\n",
    "The genre dataframe contains the unique genres from all the combined dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b41aa38c-0a80-4679-9a0b-6af173a76e68",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|GenreName|\n",
      "+---------+\n",
      "|    Crime|\n",
      "|  Romance|\n",
      "|    Drama|\n",
      "|   Family|\n",
      "|   Comedy|\n",
      "+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Explode genres into multiple rows\n",
    "genre_df = combined_df.select(\n",
    "    col(\"title\"),\n",
    "    explode(split(col(\"genres\"), \",\\\\s*\")).alias(\"GenreName\")\n",
    ")\n",
    "\n",
    "# Extract unique genres\n",
    "unique_genres_df = genre_df.select(\"GenreName\").distinct()\n",
    "\n",
    "unique_genres_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dfd27897-4843-49f2-9680-dd93d059c4bc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Country DataFrame\n",
    "The country dataframe contains the unique countries from the combined dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "541e3e18-1f46-4ca7-8a71-168fea669137",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n",
      "|CountryCode|\n",
      "+-----------+\n",
      "|         PF|\n",
      "|         AT|\n",
      "|         AD|\n",
      "|         DE|\n",
      "|         ZA|\n",
      "+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Explode countries into multiple rows\n",
    "country_df = combined_df.select(\n",
    "    col(\"title\"),\n",
    "    explode(split(col(\"availableCountries\"), \",\\\\s*\")).alias(\"CountryCode\")\n",
    ")\n",
    "\n",
    "# Extract unique countries\n",
    "unique_countries_df = country_df.select(\"CountryCode\").distinct()\n",
    "unique_countries_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e4c8ccdb-93da-46b8-9aa8-d8a10d6b0e0a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Platform DataFrame\n",
    "The platform dataframe contains the unique countries from the Combined dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e3b34529-2f1b-4344-9517-8a2d2e2ecb7e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+\n",
      "| platformName|\n",
      "+-------------+\n",
      "| Amazon Prime|\n",
      "|Apple TV Plus|\n",
      "|      HBO Max|\n",
      "|         Hulu|\n",
      "|      Netflix|\n",
      "+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Extract unique platforms\n",
    "platform_df = combined_df.select(\n",
    "    col(\"title\"),\n",
    "    col(\"platform\").alias(\"platformName\")\n",
    ")\n",
    "\n",
    "# Extract unique genres\n",
    "unique_platform_df = platform_df.select(\"platformName\").distinct()\n",
    "unique_platform_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4eaf63b9-e70c-47a4-8df2-2b9f053128cb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Loading dataframes to SQL Server\n",
    "\n",
    "To make sure only new data is loaded on to the server the exsisting data is first put in a dataframe and joined with the new dataframe. This is done for the content, genres and country dataframes.\n",
    "\n",
    "Next ContentGenres and ContentCountries tables are created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3a87a44f-bd9d-40d2-9a79-42e66e91d8d6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Content table\n",
    "# Load Existing Table from SQL Server\n",
    "existing_content_df = spark.read.jdbc(\n",
    "    url=jdbc_url,\n",
    "    table=\"Content\",\n",
    "    properties=connection_properties\n",
    ")\n",
    "\n",
    "# Identify new records\n",
    "new_content_records_df = content_df.join(\n",
    "    existing_content_df, on=\"imdbID\", how=\"left_anti\"\n",
    ")\n",
    "\n",
    "# Write New Records to the SQL Table\n",
    "new_content_records_df.write.jdbc(\n",
    "    url=jdbc_url,\n",
    "    table=\"Content\",\n",
    "    mode=\"append\",\n",
    "    properties=connection_properties\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "91ffe691-c947-4361-9ba0-17c784d38df1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Countries table\n",
    "# Load Existing table from SQL Server\n",
    "existing_countries_df = spark.read.jdbc(\n",
    "    url=jdbc_url,\n",
    "    table=\"Countries\",\n",
    "    properties=connection_properties\n",
    ")\n",
    "\n",
    "# Identify new records\n",
    "new_country_records_df = unique_countries_df.join(\n",
    "    existing_countries_df, on=\"CountryCode\", how=\"left_anti\"\n",
    ")\n",
    "\n",
    "# Write New Records to the SQL Table\n",
    "new_country_records_df.write.jdbc(\n",
    "    url=jdbc_url,\n",
    "    table=\"Countries\",\n",
    "    mode=\"append\",\n",
    "    properties=connection_properties\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7ef8d584-093d-4c69-b4e6-fd16700db318",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Genres table\n",
    "# Load Existing table from SQL Server\n",
    "existing_genres_df = spark.read.jdbc(\n",
    "    url=jdbc_url,\n",
    "    table=\"Genres\",\n",
    "    properties=connection_properties\n",
    ")\n",
    "\n",
    "# Identify new records\n",
    "new_genre_records_df = unique_genres_df.join(\n",
    "    existing_genres_df, on=\"GenreName\", how=\"left_anti\"\n",
    ")\n",
    "\n",
    "# Write New Records to the SQL Table\n",
    "new_genre_records_df.write.jdbc(\n",
    "    url=jdbc_url,\n",
    "    table=\"Genres\",\n",
    "    mode=\"append\",\n",
    "    properties=connection_properties\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b59e6600-a237-40e2-90e2-ba6a02f34689",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Platform table\n",
    "# Load Existing table from SQL Server\n",
    "existing_platform_df = spark.read.jdbc(\n",
    "    url=jdbc_url,\n",
    "    table=\"Platforms\",\n",
    "    properties=connection_properties\n",
    ")\n",
    "\n",
    "# Identify new records\n",
    "new_platform_records_df = unique_platform_df.join(\n",
    "    existing_platform_df, on=\"platformName\", how=\"left_anti\"\n",
    ")\n",
    "\n",
    "# Write New Records to the SQL Table\n",
    "new_platform_records_df.write.jdbc(\n",
    "    url=jdbc_url,\n",
    "    table=\"Platforms\",\n",
    "    mode=\"append\",\n",
    "    properties=connection_properties\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "62c65dd5-13a1-475d-bd8f-a816015c9c55",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# ContentGenres table\n",
    "\n",
    "# Explode genres into multiple rows and select the required columns\n",
    "content_genres_df = combined_df.select(\n",
    "    col(\"imdbId\").alias(\"contentID\"), \n",
    "    explode(split(col(\"genres\"), \",\")).alias(\"genreName\")\n",
    ").distinct()\n",
    "\n",
    "# Create or replace a temporary view\n",
    "content_genres_df.createOrReplaceTempView(\"temp_content_genres\")\n",
    "\n",
    "# Create temporary views for existing tables\n",
    "existing_content_df.createOrReplaceTempView(\"Content\")\n",
    "existing_genres_df.createOrReplaceTempView(\"Genres\")\n",
    "\n",
    "# Perform the join and select the required columns\n",
    "content_genres_result_df = spark.sql(\"\"\"\n",
    "SELECT c.contentID, g.genreID\n",
    "FROM temp_content_genres cg\n",
    "JOIN Content c ON c.imdbId = cg.contentID\n",
    "JOIN Genres g ON g.genreName = cg.genreName\n",
    "\"\"\")\n",
    "\n",
    "# Write the result DataFrame to the SQL Server table\n",
    "content_genres_result_df.write.jdbc(\n",
    "    url=jdbc_url,\n",
    "    table=\"ContentGenres\",\n",
    "    mode=\"overwrite\",\n",
    "    properties=connection_properties\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7cfb8216-24c6-4d7d-ad25-531bcb0cecee",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# ContentCountries table\n",
    "\n",
    "# Explode countries into multiple rows and select the required columns\n",
    "content_countries_df = combined_df.select(\n",
    "    col(\"imdbId\").alias(\"contentID\"), \n",
    "    explode(split(col(\"availableCountries\"), \",\")).alias(\"countryCode\")\n",
    ").distinct()\n",
    "\n",
    "# Create or replace a temporary view\n",
    "content_countries_df.createOrReplaceTempView(\"temp_content_countries\")\n",
    "\n",
    "# Create temporary views for existing tables\n",
    "existing_content_df.createOrReplaceTempView(\"Content\")\n",
    "existing_countries_df.createOrReplaceTempView(\"Countries\")\n",
    "\n",
    "# Perform the join and select the required columns\n",
    "content_countries_result_df = spark.sql(\"\"\"\n",
    "SELECT c.contentID, co.countryID\n",
    "FROM temp_content_countries cc\n",
    "JOIN Content c ON c.imdbId = cc.contentID\n",
    "JOIN Countries co ON co.countryCode = cc.countryCode\n",
    "\"\"\")\n",
    "\n",
    "# Write the result DataFrame to the SQL Server table\n",
    "content_countries_result_df.write.jdbc(\n",
    "    url=jdbc_url,\n",
    "    table=\"ContentCountries\",\n",
    "    mode=\"overwrite\",\n",
    "    properties=connection_properties\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8d11baf8-d320-4a17-ac78-c7f920575bab",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# ContentPlatform table\n",
    "\n",
    "# Explode platforms into multiple rows and select the required columns\n",
    "content_platform_df = combined_df.select(\n",
    "    col(\"imdbId\").alias(\"contentID\"), \n",
    "    col(\"platform\").alias(\"platformName\")\n",
    ").distinct()\n",
    "\n",
    "# Create or replace a temporary view\n",
    "content_platform_df.createOrReplaceTempView(\"temp_content_platforms\")\n",
    "\n",
    "# Create temporary views for existing tables\n",
    "existing_content_df.createOrReplaceTempView(\"Content\")\n",
    "existing_platform_df.createOrReplaceTempView(\"Platforms\")\n",
    "\n",
    "# Perform the join and select the required columns\n",
    "content_platform_result_df = spark.sql(\"\"\"\n",
    "SELECT c.contentID, p.platformID\n",
    "FROM temp_content_platforms cp\n",
    "JOIN Content c ON c.imdbId = cp.contentID\n",
    "JOIN Platforms p ON p.platformName = cp.platformName\n",
    "\"\"\")\n",
    "\n",
    "# Write the result DataFrame to the SQL Server table\n",
    "content_platform_result_df.write.jdbc(\n",
    "    url=jdbc_url,\n",
    "    table=\"ContentPlatform\",\n",
    "    mode=\"overwrite\",\n",
    "    properties=connection_properties\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "client": "1"
   },
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 2700231208197253,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 2
   },
   "notebookName": "dataset-etl-v1",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
